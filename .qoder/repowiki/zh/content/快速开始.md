# 快速开始

<cite>
**本文档中引用的文件**  
- [README.md](file://README.md)
- [libs/core/README.md](file://libs/core/README.md)
- [libs/langchain/README.md](file://libs/langchain/README.md)
- [libs/partners/ollama/langchain_ollama/chat_models.py](file://libs/partners/ollama/langchain_ollama/chat_models.py)
- [libs/core/langchain_core/vectorstores/base.py](file://libs/core/langchain_core/vectorstores/base.py)
</cite>

## 目录
1. [简介](#简介)
2. [安装 LangChain](#安装-langchain)
3. [基础用法：聊天模型与提示模板](#基础用法聊天模型与提示模板)
4. [进阶用法：检索器与链](#进阶用法检索器与链)
5. [构建智能体（Agent）](#构建智能体agent)
6. [故障排除](#故障排除)
7. [总结](#总结)

## 简介
LangChain 是一个用于构建由大语言模型（LLM）驱动的应用程序的框架。它通过提供标准化接口，帮助开发者将 LLM 与各种数据源、工具和外部系统连接起来，从而简化 AI 应用的开发流程。本指南将引导初学者从零开始构建他们的第一个 LangChain 应用，逐步介绍从安装到构建智能体的完整流程。

## 安装 LangChain
要开始使用 LangChain，首先需要通过 pip 安装主包。这是使用 LangChain 的第一步。

```bash
pip install langchain
```

此命令将安装 LangChain 的核心功能及其依赖项。安装完成后，您就可以在 Python 环境中导入并使用 LangChain 的各种组件了。

**Section sources**
- [README.md](file://README.md#L1-L78)

## 基础用法：聊天模型与提示模板
在本节中，我们将创建一个最简单的 LangChain 应用，它使用聊天模型生成回复。我们将以 Ollama 为例来演示如何加载模型和创建提示。

### 加载聊天模型
首先，您需要加载一个聊天模型。LangChain 支持多种模型提供商，包括 OpenAI 和 Ollama。以下代码展示了如何使用 Ollama 加载一个聊天模型：

```python
from langchain_ollama import ChatOllama

# 初始化 Ollama 聊天模型
llm = ChatOllama(model="llama3.1", temperature=0.7)
```

### 创建提示模板
提示模板（Prompt Template）是向 LLM 提供结构化输入的工具。您可以使用 `ChatPromptTemplate` 来创建一个包含变量的模板。

```python
from langchain_core.prompts import ChatPromptTemplate

# 创建一个聊天提示模板
prompt = ChatPromptTemplate.from_messages([
    ("system", "你是一个有帮助的助手。"),
    ("human", "请解释一下 {topic} 是什么？")
])
```

### 生成回复
最后，将提示模板与聊天模型结合，生成最终的回复。

```python
# 组合提示和模型
chain = prompt | llm

# 调用链并获取回复
response = chain.invoke({"topic": "量子计算"})
print(response.content)
```

此代码将输出一个关于“量子计算”的解释。通过这种方式，您可以轻松地将提示和模型链接起来，形成一个简单的处理链。

**Section sources**
- [libs/partners/ollama/langchain_ollama/chat_models.py](file://libs/partners/ollama/langchain_ollama/chat_models.py#L0-L49)
- [libs/core/langchain_core/prompts/base.py](file://libs/core/langchain_core/prompts/base.py#L0-L199)

## 进阶用法：检索器与链
接下来，我们将引入更复杂的组件：检索器（Retriever）和链（Chain）。这将允许您的应用从文档中获取信息，并将其与生成步骤结合起来。

### 使用检索器
检索器可以从向量数据库或其他数据源中检索相关信息。`VectorStoreRetriever` 是一个常用的检索器，它基于语义相似性来查找文档。

```python
from langchain_core.vectorstores import VectorStoreRetriever

# 假设您已经有一个向量存储实例 `vectorstore`
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 4}
)

# 使用检索器查找相关文档
docs = retriever.invoke("LangChain 的主要功能是什么？")
for doc in docs:
    print(doc.page_content)
```

### 构建检索链
现在，我们可以将检索器与聊天模型结合，创建一个检索增强生成（RAG）链。这将使模型能够基于检索到的文档生成更准确的回复。

```python
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# 创建一个检索链
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# 调用链并获取回复
final_response = rag_chain.invoke("LangChain 的主要功能是什么？")
print(final_response)
```

此链首先使用检索器获取与问题相关的上下文，然后将上下文和问题一起传递给提示模板，最后由聊天模型生成回复。

**Section sources**
- [libs/core/langchain_core/vectorstores/base.py](file://libs/core/langchain_core/vectorstores/base.py#L895-L963)

## 构建智能体（Agent）
智能体（Agent）是 LangChain 中最强大的功能之一。它能够使用工具（如搜索）来回答问题，从而实现更复杂的任务。

### 创建工具
首先，您需要定义智能体可以使用的工具。例如，一个简单的搜索工具：

```python
from langchain_core.tools import tool

@tool
def search(query: str) -> str:
    """搜索给定查询的相关信息。"""
    # 这里可以集成实际的搜索引擎
    return f"搜索结果：关于 {query} 的信息。"
```

### 初始化智能体
使用 `create_retriever_tool` 或自定义工具来初始化一个智能体。

```python
from langchain.agents import create_openai_tools_agent
from langchain_core.agents import AgentExecutor

# 假设您使用的是支持工具调用的模型
tools = [search]
agent = create_openai_tools_agent(llm, tools, prompt)

# 创建智能体执行器
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

# 运行智能体
result = agent_executor.invoke({"input": "最近的 AI 技术进展有哪些？"})
print(result["output"])
```

这个智能体将能够决定何时调用搜索工具，并利用搜索结果来生成最终的回答。

**Section sources**
- [libs/langchain/langchain_classic/agents/agent_toolkits/__init__.py](file://libs/langchain/langchain_classic/agents/agent_toolkits/__init__.py#L133-L166)

## 故障排除
在使用 LangChain 时，可能会遇到一些常见问题。以下是一些解决方案：

- **模块未安装**：如果出现 `ImportError`，请确保已通过 `pip install` 安装了相应的包。例如，使用 Ollama 时，需要安装 `langchain-ollama`。
- **API 密钥问题**：对于需要 API 密钥的模型（如 OpenAI），请确保已正确设置环境变量 `OPENAI_API_KEY`。
- **模型加载失败**：检查模型名称是否正确，并确保本地模型服务器（如 Ollama）正在运行。

## 总结
本指南介绍了如何从零开始构建一个 LangChain 应用。我们从安装开始，逐步介绍了聊天模型、提示模板、检索器、链和智能体的使用方法。通过这些组件，您可以构建出功能强大且灵活的 LLM 应用程序。随着您对 LangChain 的深入了解，可以探索更多高级功能，如 LangGraph 和 LangSmith，以进一步提升应用的性能和可靠性。